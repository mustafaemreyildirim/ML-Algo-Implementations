{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/cloudera/parcels/SPARK2/lib/spark2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('emre').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://azheds01.allianz-tr.local:4054\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0.cloudera2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>emre</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb501f86748>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = spark.createDataFrame([\n",
    "    (0, \"s p a r k\", 1.0),\n",
    "    (1, \"h a d o o p\", 0.0),\n",
    "    (2, \"s p a \", 1.0),\n",
    "    (3, \"h a d\", 0.0),\n",
    "    (4, \"h p a\", 0.0) ], [\"id\",\"text\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam = 0.01)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.createDataFrame([\n",
    "    (5, \"s r k\"),\n",
    "    (6, \"h d p\"),\n",
    "    (7, \"s p\"),\n",
    "    (8, \"h o\"),\n",
    "    (9, \"p a\"),\n",
    "    (10, \"h\"),\n",
    "    (11, \"b a\"),\n",
    "    (11, \"a\"),\n",
    "    (11, \"k\") ], [\"id\", \"text\"] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+--------------------+--------------------+--------------------+----------+\n",
      "| id| text|    words|            features|       rawPrediction|         probability|prediction|\n",
      "+---+-----+---------+--------------------+--------------------+--------------------+----------+\n",
      "|  5|s r k|[s, r, k]|(262144,[94533,18...|[-4.1608207512036...|[0.01535529127490...|       1.0|\n",
      "|  6|h d p|[h, d, p]|(262144,[15554,27...|[4.25643402140950...|[0.98602530771388...|       0.0|\n",
      "|  7|  s p|   [s, p]|(262144,[94533,21...|[-3.1757954008034...|[0.04008681384656...|       1.0|\n",
      "|  8|  h o|   [h, o]|(262144,[15554,25...|[4.25344479429933...|[0.98598405805862...|       0.0|\n",
      "|  9|  p a|   [p, a]|(262144,[213268,2...|[0.02378038883240...|[0.50594481705782...|       0.0|\n",
      "| 10|    h|      [h]|(262144,[15554],[...|[3.91481408071616...|[0.98044573887328...|       0.0|\n",
      "| 11|  b a|   [b, a]|(262144,[30913,22...|[0.62478957358150...|[0.65130707705009...|       0.0|\n",
      "| 11|    a|      [a]|(262144,[227410],...|[0.62478957358150...|[0.65130707705009...|       0.0|\n",
      "| 11|    k|      [k]|(262144,[227520],...|[-0.1682276939931...|[0.45804198279762...|       1.0|\n",
      "+---+-----+---------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.transform(test)\n",
    "prediction.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
